import psycopg2.pool
from decouple import config
from fastapi import FastAPI
from openai import OpenAI
from pydantic import BaseModel
import uvicorn

# database imports
from database import transactions, conversations, users, transaction_categories, transaction_details, payment_methods, roles

# Load database credentials from .env file
dbname = config('DB_NAME')
user = config('DB_USER')
password = config('DB_PASSWORD')
host = config('DB_HOST')
port = config('DB_PORT')

# connection pool
connection_pool = psycopg2.pool.SimpleConnectionPool(
    minconn=1,
    maxconn=5,
    dbname=dbname,
    user=user,
    password=password,
    host=host,
    port=port
)

# FastAPI instance
app = FastAPI()

# OpenAI instance
openai = OpenAI(
    api_key = config('OPENAI_API_KEY')
)

# message response
class MessageResponse(BaseModel):
    user_id: int
    content: str
    role: str = "assistant"

# incoming message
class IncomingMessage(BaseModel):
    user_id: int
    content: str
    role: str = "user"

# incoming message endpoint
@app.get("/incoming-message")
async def incoming_message(message: IncomingMessage):
    # store message in database
    conn = connection_pool.getconn()
    conversations.insert_conversation(conn, message.model_dump())
    connection_pool.putconn(conn)

    # determine whether the question is about the past or the future with OpenAI
    prompt = [{"role": "user", "content": "determine whether the question is about the past or the future "+message.content+" reply 0 for past and 1 for future"}]
    response = openai.chat.completions.create(
      model="gpt-3.5-turbo",
      messages=prompt,
      max_tokens=300
    )
    time = int(response.choices[0].message.content)

    # past
    if time == 0:
        # check if the message requires queries
        prompt = [{"role": "user", "content": "the messages are for a finance chatbot connected to a database. the database has a transaction table with the columns: transaction_id, user_id, date, transaction_detail, description, transaction_category, payment_method, amount. check if an SQL query is necessary to respond to the following: "+message.content+" reply 0 for no and 1 for yes"}]
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=prompt,
            max_tokens=300
        )
        if int(response.choices[0].message.content) == 1:
            # generate the query
            prompt = [{"role": "user", "content": "the messages are for a finance chatbot connected to a database. the database has a transaction table with the columns: transaction_id, user_id, date, transaction_detail, description, transaction_category, payment_method, amount. generate a PostgreSQL query string to respond to the following: "+message.content}]
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=prompt,
                max_tokens=300
            )
            query = response.choices[0].message.content
            print(query)
            
            # execute the query
            conn = connection_pool.getconn()
            cursor = conn.cursor()
            cursor.execute(query)
            result = cursor.fetchall()
            cursor.close()
            connection_pool.putconn(conn)

            # create a response
            prompt = [{"role": "user", "content": "the messages are for a finance chatbot connected to a database. the database has a transaction table with the columns: transaction_id, user_id, date, transaction_detail, description, transaction_category, payment_method, amount. The following question was asked: "+message.content+" the following output was generated by database query: "+str(result)+". provide a response to the user"}]
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=prompt,
                max_tokens=300
            )
            answer = response.choices[0].message.content
            print(answer)
            answer = MessageResponse(user_id=message.user_id, content=answer)
            conn = connection_pool.getconn()
            conversations.insert_conversation(conn, answer.model_dump())
            connection_pool.putconn(conn)
            return answer.model_dump()

if __name__ == '__main__':
    uvicorn.run("main:app")